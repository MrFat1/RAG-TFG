{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842c4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q transformers\n",
    "!pip install -q langchain\n",
    "!pip install -U -q langchain-community\n",
    "!pip install -q bitsandbytes\n",
    "!pip install -q sentence_transformers\n",
    "!pip install -q unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54a272d8-a547-43c0-b2fa-7e1d8f8a8d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.41.1\n",
      "- Platform: Windows-10-10.0.22621-SP0\n",
      "- Python version: 3.11.9\n",
      "- Huggingface_hub version: 0.23.1\n",
      "- Safetensors version: 0.4.3\n",
      "- Accelerate version: 0.30.1\n",
      "- Accelerate config: \tnot found\n",
      "- PyTorch version (GPU?): 2.3.0+cu121 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbea2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8539f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name='meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b75ac1-00e2-449d-a885-dd2fa8e271b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"bfloat16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Device partition\n",
    "device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ede365c-64e2-4797-bf02-7ac367fcbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638269f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage = True,\n",
    "    device_map = device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b402052",
   "metadata": {},
   "source": [
    "### LangChain config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6e359d-f84c-4805-999b-28ed270193d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\" # Where to store the database\n",
    "DATA_PATH = \"data\" # Path to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892b9935-95ff-4ce5-8477-459b52150893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Load all the documents in a dictionary and add XML tags as fields inside the dictionary\n",
    "def XMLLoader(folder_path):\n",
    "    reportData_list = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.xml'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            soup = BeautifulSoup(content, 'xml')\n",
    "\n",
    "            reportData = {}\n",
    "            for tag in soup.find_all():\n",
    "                if tag.name != \"report\":\n",
    "                    reportData[tag.name] = tag.text.strip()\n",
    "\n",
    "            reportData[\"filename\"] = filename\n",
    "            reportData_list.append(reportData)\n",
    "\n",
    "    return reportData_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc1ce53-5cc9-4846-b9d6-d3cc6e073fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  XMLLoader(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32be7ebc-8a1d-4dc6-a2a2-03e2096bfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Create a \"Document\" class from LangChain and add all the tags as document metadata\n",
    "documents = []\n",
    "for doc in data:\n",
    "\n",
    "    document = Document(page_content=doc[\"report_text\"], metadata={\"source\": doc[\"filename\"],\n",
    "                                                                   \"subtype\": doc[\"subtype\"],\n",
    "                                                                   \"type\": doc[\"type\"],\n",
    "                                                                   \"chief_complaint\": doc[\"chief_complaint\"],\n",
    "                                                                   \"admit_diagnosis\": doc[\"admit_diagnosis\"],\n",
    "                                                                   \"discharge_diagnosis\": doc[\"discharge_diagnosis\"],\n",
    "                                                                   \"year\": doc[\"year\"],\n",
    "                                                                   \"downlaod_time\": doc.get(\"download_time\", \"\"), # Algunos no tiemem este campo\n",
    "                                                                   \"deid\": doc[\"deid\"]})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9cff44-6003-4f62-90a9-362b2865afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc85c5-6f4a-40b3-9283-0bdbd3830fba",
   "metadata": {},
   "source": [
    "### Parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4f5dcf-697e-4ee2-bd16-ea9dd6af67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "parent_docs =  documents\n",
    "\n",
    "embedding_model = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "# https://huggingface.co/sentence-transformers\n",
    "# https://huggingface.co/spaces/mteb/leaderboard\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d07827-413d-40b6-9ce4-98adf317700c",
   "metadata": {},
   "source": [
    "### Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f51eaa-5848-4427-bf93-9c10ca4fa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=0,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "#chunks = text_splitter.split_documents(documents)\n",
    "#print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60216357-0f5d-43a4-a3ea-da3d081ccaef",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8302eb2-137c-4e82-a813-f79973126da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear out the database first if already exists.\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "store = InMemoryStore()\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=CHROMA_PATH)\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore, # For child chunks\n",
    "    docstore=store, # For main documents\n",
    "    child_splitter=child_splitter,\n",
    "    search_kwargs={\"k\": 1}\n",
    ")\n",
    "\n",
    "parent_document_retriever.add_documents(parent_docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbea40c-706b-4f8c-abe3-07fe8f488e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent chunks (Number of reports): 41\n",
      "Child chunks: 178\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parent chunks (Number of reports): {len(list(store.yield_keys()))}\")\n",
    "print(f\"Child chunks: {len(parent_document_retriever.vectorstore.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c3c12-aaf3-4086-af64-2eeca867218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB keys\n",
    "#parent_document_retriever.vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a5a747-eb9e-48b3-88d7-52245aea7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_model():\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.1,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=True,\n",
    "        max_new_tokens=300,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "    return hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fd978d-fdc6-4a3e-a67b-684e1ec4eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from rom langchain-huggingface package and should be used instead. To use it run `pip install -U from rom langchain-huggingface` and import as `from from rom langchain_huggingface import llms import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b25050-8eb4-4f11-aaee-adafa485b4a0",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb4a508-0e2f-4a28-b84b-a6a50a55dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "You are an expert doctor. Use the information in the medical report provided below to answer the query.\n",
    "\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Medical report:\n",
    "{context}\n",
    "\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7fba54-821b-4dab-a31a-dc0a1f838494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_docs = vectorstore.similarity_search(\"Medications of Andrew Ying\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92577427-7fab-4c63-8676-cf6f524c4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "544d2d2b-64ba-41c7-8969-4a1cc782c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": parent_document_retriever })\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL language to create the chain (de izquierda a derecha el output de uno se pasa al otro)\n",
    "parent_retrieval_chain = setup_and_retrieval | rag_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37ae6ad4-907d-4b9c-9d62-f566c7819614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "You are an expert doctor. Use the information in the medical report provided below to answer the query.\n",
      "\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Medical report:\n",
      "[Document(page_content='[Report de-identified (Safe-harbor compliant) by De-ID v.6.22.07.0]\\n\\nCONSULTATION REPORT\\nMercy Hospital\\nChicago, IL 60612\\n__________________________________________________\\n\\nMark Johnson\\n246810121\\n246810121\\nC1A/3 ___________________________________________________\\n\\nDATE OF CONSULTATION:    May 24, 2024\\n\\nCONSULTING PHYSICIAN:    Dr. Jessica Brown, M.D.\\n\\nATTENDING PHYSICIAN:     Dr. James Wilson, M.D.\\n\\nREQUESTING PHYSICIAN:   Dr. Natalie Green, M.D.\\n\\nGASTROENTEROLOGY\\n\\nREASON FOR CONSULTATION \\nSevere abdominal pain and bloating.\\n\\nHISTORY OF PRESENT ILLNESS\\nThis is a 55-year-old Caucasian man with a history of diverticulosis and diabetes mellitus. He was admitted with severe lower abdominal pain, bloating, and nausea. The pain has been persistent for the past three days and is not relieved by over-the-counter medications. He denies any vomiting, fever, or changes in bowel habits. He has been on a clear liquid diet since admission.\\n\\nPAST MEDICAL & SURGICAL HISTORY\\n1. Diverticulosis.\\n2. Diabetes mellitus.\\n3. Hypertension.\\n4. Anemia.\\n5. Appendectomy.\\n\\nFAMILY HISTORY \\nHis mother had a history of colorectal cancer. No other significant family history.\\n\\nSOCIAL HISTORY \\nThe patient works as an accountant. He does not smoke and consumes alcohol occasionally. He is married and has two children.\\n\\nCURRENT MEDICATIONS \\n1. Metformin 1000 mg twice daily.\\n2. Lisinopril 20 mg daily.\\n3. Iron supplements.\\n4. Ibuprofen as needed for pain.\\n\\nLABORATORY DATA \\nWBC count 12.0, hemoglobin 13.0, hematocrit 39.0, platelet count 220. Sodium 139, potassium 4.0, chloride 100, bicarbonate 24, BUN 15, creatinine 1.0. Blood glucose 180. CRP elevated at 12.5.\\n\\nDIAGNOSTICS \\nCT scan of the abdomen shows diverticulitis with localized abscess formation.\\n\\nPHYSICAL EXAMINATION \\nVITALS: Blood pressure is 130/80, temperature 37.5, pulse 85, respiratory rate 18. HEENT: Normocephalic/atraumatic, no jaundice. ABDOMEN: Distended, tender in the lower quadrants, positive rebound tenderness. Bowel sounds present but hypoactive. EXTREMITIES: No edema. NEUROLOGIC: Alert and oriented, no focal deficits.\\n\\nASSESSMENT/RECOMMENDATIONS \\n1. Acute diverticulitis with abscess formation.\\na) Continue IV antibiotics.\\nb) Surgical consultation for possible drainage.\\nc) Maintain on a clear liquid diet and advance as tolerated.\\n\\n2. Diabetes mellitus.\\na) Monitor blood glucose levels closely.\\nb) Adjust insulin as needed.\\n\\n3. Hypertension.\\na) Continue current antihypertensive regimen.\\n\\n4. Anemia.\\na) Monitor hemoglobin levels.\\nb) Continue iron supplements.\\n\\nThank you for the opportunity to assist in the care of this patient. Please contact us for any further assistance.\\n\\n__________________________________\\nDr. Jessica Brown, M.D.\\n\\nDict:     May 24, 2024 10:00:00\\nTran:     May 24, 2024 10:30:00\\nJB\\n\\nR:  May 24, 2024 11:00:00/jb\\n\\nDr. James Wilson, M.D., <Attending>\\nDr. Jessica Brown, M.D.\\n          \\nDocument authenticated by: Dr. Jessica Brown, M.D., on May 24, 2024 12:00:00 ET.', metadata={'source': 'syntheticReport3.xml', 'subtype': 'CONSULT', 'type': 'HP', 'chief_complaint': 'ABDOMINAL PAIN', 'admit_diagnosis': '789.00', 'discharge_diagnosis': '562.10,285.1,401.1,250.00', 'year': '2024', 'downlaod_time': '', 'deid': 'v.6.22.07.0'})]\n",
      "\n",
      "\n",
      "Query:\n",
      "Laboratory data of Mark Johnson\n",
      "\n",
      "Please provide the laboratory data of Mark Johnson from the medical report provided above. \n",
      "\n",
      "Answer:\n",
      "The laboratory data of Mark Johnson is:\n",
      "\n",
      "WBC count 12.0\n",
      "hemoglobin 13.0\n",
      "hematocrit 39.0\n",
      "platelet count 220\n",
      "sodium 139\n",
      "potassium 4.0\n",
      "chloride 100\n",
      "bicarbonate 24\n",
      "BUN 15\n",
      "creatinine 1.0\n",
      "blood glucose 180\n",
      "CRP elevated at 12.5.\n"
     ]
    }
   ],
   "source": [
    "out = parent_retrieval_chain.invoke(\"Laboratory data of Mark Johnson\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb4507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
