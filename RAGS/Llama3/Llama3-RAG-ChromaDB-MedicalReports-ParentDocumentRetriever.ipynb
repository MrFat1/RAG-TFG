{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "842c4bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q chromadb\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q transformers\n",
    "!pip install -q langchain\n",
    "!pip install -U -q langchain-community\n",
    "!pip install -q bitsandbytes\n",
    "!pip install -q sentence_transformers\n",
    "!pip install -q unstructured\n",
    "!pip install -q accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a272d8-a547-43c0-b2fa-7e1d8f8a8d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copy-and-paste the text below in your GitHub issue and FILL OUT the two last points.\n",
      "\n",
      "- `transformers` version: 4.41.2\n",
      "- Platform: Windows-10-10.0.22621-SP0\n",
      "- Python version: 3.11.9\n",
      "- Huggingface_hub version: 0.23.2\n",
      "- Safetensors version: 0.4.3\n",
      "- Accelerate version: not installed\n",
      "- Accelerate config: not found\n",
      "- PyTorch version (GPU?): 2.3.0+cu121 (True)\n",
      "- Tensorflow version (GPU?): not installed (NA)\n",
      "- Flax version (CPU?/GPU?/TPU?): not installed (NA)\n",
      "- Jax version: not installed\n",
      "- JaxLib version: not installed\n",
      "- Using GPU in script?: <fill in>\n",
      "- Using distributed or parallel set-up in script?: <fill in>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbea2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8539f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name='meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b75ac1-00e2-449d-a885-dd2fa8e271b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"bfloat16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "# Device partition\n",
    "device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ede365c-64e2-4797-bf02-7ac367fcbacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "638269f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    low_cpu_mem_usage = True,\n",
    "    device_map = device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b402052",
   "metadata": {},
   "source": [
    "### LangChain config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba6e359d-f84c-4805-999b-28ed270193d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROMA_PATH = \"chroma\" # Where to store the database\n",
    "DATA_PATH = \"data\" # Path to the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892b9935-95ff-4ce5-8477-459b52150893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Load all the documents in a dictionary and add XML tags as fields inside the dictionary\n",
    "def XMLLoader(folder_path):\n",
    "    reportData_list = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.xml'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            with open(file_path, 'r') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            soup = BeautifulSoup(content, 'xml')\n",
    "\n",
    "            reportData = {}\n",
    "            for tag in soup.find_all():\n",
    "                if tag.name != \"report\":\n",
    "                    reportData[tag.name] = tag.text.strip()\n",
    "\n",
    "            reportData[\"filename\"] = filename\n",
    "            reportData_list.append(reportData)\n",
    "\n",
    "    return reportData_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adc1ce53-5cc9-4846-b9d6-d3cc6e073fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  XMLLoader(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32be7ebc-8a1d-4dc6-a2a2-03e2096bfe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Create a \"Document\" class from LangChain and add all the tags as document metadata\n",
    "documents = []\n",
    "for doc in data:\n",
    "\n",
    "    document = Document(page_content=doc[\"report_text\"], metadata={\"source\": doc[\"filename\"],\n",
    "                                                                   \"subtype\": doc[\"subtype\"],\n",
    "                                                                   \"type\": doc[\"type\"],\n",
    "                                                                   \"chief_complaint\": doc[\"chief_complaint\"],\n",
    "                                                                   \"admit_diagnosis\": doc[\"admit_diagnosis\"],\n",
    "                                                                   \"discharge_diagnosis\": doc[\"discharge_diagnosis\"],\n",
    "                                                                   \"year\": doc[\"year\"],\n",
    "                                                                   \"downlaod_time\": doc.get(\"download_time\", \"\"), # Algunos no tiemem este campo\n",
    "                                                                   \"deid\": doc[\"deid\"]})\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c9cff44-6003-4f62-90a9-362b2865afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc85c5-6f4a-40b3-9283-0bdbd3830fba",
   "metadata": {},
   "source": [
    "### Parent document retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d4f5dcf-697e-4ee2-bd16-ea9dd6af67b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "parent_docs =  documents\n",
    "\n",
    "embedding_model = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "# https://huggingface.co/sentence-transformers\n",
    "# https://huggingface.co/spaces/mteb/leaderboard\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d07827-413d-40b6-9ce4-98adf317700c",
   "metadata": {},
   "source": [
    "### Text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f51eaa-5848-4427-bf93-9c10ca4fa1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 400\n",
    "\n",
    "child_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "    tokenizer,\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=40,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "#chunks = text_splitter.split_documents(documents)\n",
    "#print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60216357-0f5d-43a4-a3ea-da3d081ccaef",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8302eb2-137c-4e82-a813-f79973126da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Clear out the database first if already exists.\n",
    "if os.path.exists(CHROMA_PATH):\n",
    "    shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "store = InMemoryStore()\n",
    "vectorstore = Chroma(embedding_function=embeddings, persist_directory=CHROMA_PATH)\n",
    "\n",
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore, # For child chunks\n",
    "    docstore=store, # For main documents\n",
    "    child_splitter=child_splitter,\n",
    "    search_kwargs={\"k\": 1}\n",
    ")\n",
    "\n",
    "parent_document_retriever.add_documents(parent_docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbea40c-706b-4f8c-abe3-07fe8f488e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent chunks (Number of reports): 41\n",
      "Child chunks: 217\n"
     ]
    }
   ],
   "source": [
    "print(f\"Parent chunks (Number of reports): {len(list(store.yield_keys()))}\")\n",
    "print(f\"Child chunks: {len(parent_document_retriever.vectorstore.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4c3c12-aaf3-4086-af64-2eeca867218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB keys\n",
    "#parent_document_retriever.vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a5a747-eb9e-48b3-88d7-52245aea7659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_model():\n",
    "    text_generation_pipeline = pipeline(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        task=\"text-generation\",\n",
    "        temperature=0.1,\n",
    "        repetition_penalty=1.1,\n",
    "        return_full_text=True,\n",
    "        max_new_tokens=300,\n",
    "        do_sample=True\n",
    "    )\n",
    "\n",
    "    hf = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "    return hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1fd978d-fdc6-4a3e-a67b-684e1ec4eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\201902452\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b25050-8eb4-4f11-aaee-adafa485b4a0",
   "metadata": {},
   "source": [
    "### Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb4a508-0e2f-4a28-b84b-a6a50a55dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "You are an expert doctor. Use the information in the medical report provided below to answer the query as a doctor would do it.\n",
    "\n",
    "If the information is not in the report, just say that you don't know. Don't try to make up an answer.\n",
    "\n",
    "Medical report:\n",
    "{context}\n",
    "\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TEMPLATE2 = \"\"\"\n",
    "    <|start_header_id|>system<|end_header_id|> \n",
    "    You are an expert doctor. Use the information in the medical report provided below to answer the query.\n",
    "    If the information is not in the report, just say that you don't know. Don't try to make up an answer.\n",
    "    \n",
    "    Medical report:\n",
    "    {context}\n",
    "    \n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>user<|end_header_id|> Query: {question}<|eot_id|>\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d7fba54-821b-4dab-a31a-dc0a1f838494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_docs = vectorstore.similarity_search(\"Medications of Jane Doe\", k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92577427-7fab-4c63-8676-cf6f524c4214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sub_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "544d2d2b-64ba-41c7-8969-4a1cc782c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": parent_document_retriever })\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# LCEL language to create the chain (de izquierda a derecha el output de uno se pasa al otro)\n",
    "parent_retrieval_chain = setup_and_retrieval | rag_prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37ae6ad4-907d-4b9c-9d62-f566c7819614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "    <|start_header_id|>system<|end_header_id|> \n",
      "    You are an expert doctor. Use the information in the medical report provided below to answer the query as a doctor would do it.\n",
      "    If the information is not in the report, just say that you don't know. Don't try to make up an answer.\n",
      "    \n",
      "    Medical report:\n",
      "    [Document(page_content=\"[Report de-identified (Safe-harbor compliant) by De-ID v.7.01.24.0]\\n\\n**INSTITUTION\\nEMERGENCY DEPARTMENT\\nPATIENT NAME: Andrew Ying\\nACCOUNT #: 789012\\nDATE OF SERVICE: May 24 2024\\nPRIMARY CARE PHYSICIAN: Dr. Jake Williams\\nATTENDING PHYSICIAN ADDENDUM:\\nThis patient was seen in conjunction with the Trauma Service as a level two \\ntrauma. I was present for the patient's initial evaluation by the Trauma \\nService. I did review the trauma flow sheet and agreed with its content \\nunless noted otherwise below.   \\nThis is a 17-year-old female patient who was the unrestrained driver in a \\nmotor vehicle collision. The vehicle reportedly flipped and did shear off a \\nutility pole. The patient denies striking her head, although she was noted \\nto have an occipital scalp laceration. She denied any loss of consciousness \\nwith this. She denies any complaints of neck pain. No chest pain. No \\nabdominal pain. She states that she is having pain at present to her right \\nupper arm, as well as her left calf. She denies any numbness or weakness in \\nher extremities. The patient's review of systems is as above. The remaining \\nsystems were negative.\\nPAST MEDICAL HISTORY:\\nNone.\\nMEDICATIONS:\\nOral contraceptives.\\nALLERGIES:\\nTHE PATIENT HAS NO KNOWN DRUG ALLERGIES. \\nTETANUS:\\nThe patient was unsure of her last tetanus immunization.\\nSOCIAL HISTORY:\\nNegative for alcohol use.  \\nPHYSICAL EXAMINATION:\\nThe patient's physical examination showed her to be awake and alert in no \\ndistress. Her GCS was 15. Vital signs upon arrival to the trauma bay showed \\nher to have a blood pressure of 122/84, pulse rate 88, respirations 16, \\noxygen saturation 98% on room air, and temperature 36.7. The patient's HEENT \\nshowed her to have a 2 cm laceration on the occipital region of the scalp. \\nHer pupils were equal and reactive. Extraocular movements were intact. The \\npatient's TMs were clear bilaterally. The patient's neck was without \\ncervical spine tenderness. The patient's oropharynx showed no evidence of \\nintraoral trauma. The chest was nontender on palpation. Breath sounds were \\nequal bilaterally. The heart was normal S1 and S2. The abdomen was soft, \\nnontender, and nondistended. The pelvis was nontender on palpation. The \\npatient did have some pain on palpation to the soft tissue of the right upper \\narm, as well as to the calf muscles in the left leg. Neurologic examination \\nshowed intact motor and sensory function.\\nED COURSE:\\nThe patient's ED course did consist of a chest x-ray showing no evidence of \\nacute rib fractures or pneumothorax. Pelvis x-ray was limited but showed no \\ngross evidence of fracture. The patient's H&H was 14.6 and 45. Glucose \\nwas 95, sodium 143, potassium 4.1. The patient did undergo a CT scan of the \\nhead showing no evidence of intracranial hemorrhage. CT scan of the cervical \\nspine was negative for any evidence of fracture or subluxation. CT scan of \\nthe chest, abdomen and pelvis ruled out fracture, thoracic or abdominal \\ninjury. The laceration was repaired by the Trauma Service with staples here \\nin the Emergency Department under my supervision. The patient did also have \\na CT scan of the thoracic spine which did have preliminary read of possible \\ncompression fracture at T8. This was relayed to the Trauma Service. The \\npatient will be admitted to the Trauma Service at this time for further \\nevaluation, management and observation.\\nADMITTING DIAGNOSIS(ES):\\n1. CLOSED HEAD INJURY.  \\n2. 2 cm OCCIPITAL SCALP LACERATION.\\n3. MULTIPLE CONTUSIONS.\\n4. POSSIBLE T8 COMPRESSION FRACTURE.\\n\\n___________________________________\\nDr. Lisa Adams, M.D.\\n\\nDictator: Dr. Lisa Adams, M.D.\\nLPA\\nD: May 24 2024 00:05:53\\nT: May 24 2024 00:16:28\\nR: May 24 2024 00:16:28/gvr\\nJob ID:  350795/789012\\nCc:\\n\\n*** Dictated By: -Dr. Samuel Brown ***\\nElectronically Signed by Dr. Lisa Adams  May 24 2024 09:10:59 AM\", metadata={'source': 'syntheticReport5.xml', 'subtype': 'EVAL', 'type': 'ER', 'chief_complaint': 'LEVEL 2/MVA', 'admit_diagnosis': '959.9', 'discharge_diagnosis': '873.0,E812.0', 'year': '2024', 'downlaod_time': '2024-05-24', 'deid': 'v.7.01.24.0'})]\n",
      "    \n",
      "    <|eot_id|>\n",
      "    <|start_header_id|>user<|end_header_id|> Query: Hello Doctor, my name is Andrew ying and my head hurts. Do you know why?<|eot_id|>assistant\n",
      "\n",
      "Good morning, Andrew! I'm Dr. Lisa Adams, your attending physician. I've reviewed your medical report, and I see that you're a 17-year-old male who was involved in a motor vehicle accident. You mentioned that your head hurts, and I'd like to take a closer look.\n",
      "\n",
      "From what I can gather from your report, you didn't strike your head during the accident, but you do have an occipital scalp laceration, which is a cut on the back of your head. We did a CT scan of your head, and it didn't show any evidence of intracranial hemorrhage or other significant injuries.\n",
      "\n",
      "However, we did find a possible compression fracture at T8, which could be contributing to your headache. Compression fractures occur when there's a sudden impact on the spine, causing one or more vertebrae to collapse. It's a common injury in car accidents, especially if the vehicle flips over.\n",
      "\n",
      "I'd like to perform a thorough examination to assess the severity of your headache and determine the best course of treatment. Can you tell me more about your headache? Is it constant, or does it come and go? Are there any specific activities that trigger or relieve your symptoms?\n",
      "\n",
      "Also, I'll need to order some additional imaging studies to confirm the diagnosis and rule out any other potential causes of your headache. We may need to consider admitting you to the hospital for further evaluation and monitoring.\n",
      "\n",
      "How does that sound, Andrew?\n"
     ]
    }
   ],
   "source": [
    "out = parent_retrieval_chain.invoke(\"Hello Doctor, my name is Andrew ying and my head hurts. Do you know why?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61fb4507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "    <|start_header_id|>system<|end_header_id|> \n",
      "    You are an expert doctor. Use the information in the medical report provided below to answer the query.\n",
      "    If the information is not in the report, just say that you don't know. Don't try to make up an answer.\n",
      "    \n",
      "    Medical report:\n",
      "    [Document(page_content='[Report de-identified (Safe-harbor compliant) by De-ID v.9.17.03.0]\\n\\nDISCHARGE SUMMARY\\nINSTITUTIONHopeville, TX 78566\\n\\nPATIENT NAME: Oliver Wharton\\nID NUMBER: 123456\\n\\nDATE OF ADMISSION:      Dec 02 2019\\n\\nDATE OF DISCHARGE:      Dec 04 2019\\n\\nDISCHARGE DIAGNOSES:\\n\\nFebrile seizure.\\nDehydration.\\nSummary:  The patient is a 2-year-old male who was admitted to the emergency room with a fever of 102.5 F and a history of a witnessed seizure.  He had been ill for 2 days with runny nose, cough, and poor oral intake.  In the emergency room, he was given fluids and fever reducers.  His seizure activity ceased and he remained afebrile for over 24 hours.\\n\\nHOSPITAL COURSE:  The patient was started on intravenous fluids and administered antibiotics for possible pneumonia.  He tolerated fluids well and his urine output improved.  He was afebrile throughout his hospitalization.  A chest x-ray was obtained which showed no acute findings.  He was weaned off of intravenous fluids and started on a regular diet by mouth.\\n\\nDISCHARGE MEDICATIONS:\\n\\nAmoxicillin 250mg twice a day for 7 days.\\nHe was given a prescription for Amoxicillin today.\\n\\nCONDITION AT THE TIME OF DISCHARGE:  Stable.\\n\\nDIET AT DISCHARGE:  Regular diet.\\n\\nACTIVITY AT DISCHARGE:  Normal activity with close monitoring for fever and return seizures.\\n\\nATTENDING PHYSICIAN: Dr. Emma Lancaster\\n\\nDict:   Dec 04 2019 14:12:51\\nTran:   Dec 04 2019 16:38:22\\nSI/jj/123456/123456\\n\\nR:  Dec 04 2019 16:38:22/jj\\n\\n**CARBON-COPY', metadata={'source': 'syntheticReport8.xml', 'subtype': 'DISCHARGE', 'type': 'PN', 'chief_complaint': 'FEVER', 'admit_diagnosis': '780.60', 'discharge_diagnosis': '780.60,079.91', 'year': '2020', 'downlaod_time': '', 'deid': 'v.9.17.03.0'})]\n",
      "    \n",
      "    <|eot_id|>\n",
      "    <|start_header_id|>user<|end_header_id|> Query: My name is Oliver Wharton and i forgot my medications. Can you help me?<|eot_id|>assistant\n",
      "\n",
      "Hello there! I'm Dr. Emma Lancaster, your attending physician during your recent hospital stay. I'd be happy to help you recall your medication schedule.\n",
      "\n",
      "According to your discharge summary, you were prescribed Amoxicillin 250mg twice a day for 7 days. It's essential to take this medication as directed to ensure proper treatment and prevent any potential complications.\n",
      "\n",
      "If you need assistance remembering when to take your medication or have any questions about its use, please don't hesitate to reach out to me or your primary care physician. We're here to support your health and well-being.\n",
      "\n",
      "Remember, it's crucial to take your medication consistently and as prescribed to achieve optimal results. If you have any concerns or issues, please don't hesitate to contact us. We're always here to help.\n",
      "\n",
      "Take care, and remember to take your medication regularly!\n"
     ]
    }
   ],
   "source": [
    "out = parent_retrieval_chain.invoke(\"My name is Oliver Wharton and i forgot my medications. Can you help me?\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889535a0-0596-488c-91a7-56fa489a4f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
